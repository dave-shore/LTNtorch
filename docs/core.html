<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ltn.core &mdash; LTNtorch 0.9 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="ltn.fuzzy_ops" href="fuzzy_ops.html" />
    <link rel="prev" title="Stable Fuzzy Semantics" href="stableconf.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> LTNtorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="grounding.html">Grounding in Logic Tensor Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="learningltn.html">Introduction to Learning in Logic Tensor Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="ltnobjects.html">LTN objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="broadcasting.html">LTN broadcasting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html#ltn-predicate-case">LTN predicate case</a></li>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html#ltn-function-case">LTN function case</a></li>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html#ltn-connective-case">LTN connective case</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quantification.html">Quantification in Logic Tensor Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quantification.html#base-quantification">Base quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantification.html#diagonal-quantification">Diagonal quantification</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantification.html#guarded-quantification">Guarded quantification</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="stableconf.html">Stable Fuzzy Semantics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Modules</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">ltn.core</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#members">Members</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="fuzzy_ops.html">ltn.fuzzy_ops</a><ul>
<li class="toctree-l2"><a class="reference internal" href="fuzzy_ops.html#members">Members</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">LTNtorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>ltn.core</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/core.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ltn-core">
<h1>ltn.core<a class="headerlink" href="#ltn-core" title="Permalink to this headline"></a></h1>
<section id="members">
<h2>Members<a class="headerlink" href="#members" title="Permalink to this headline"></a></h2>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>(value, var_labels)</p></td>
<td><p>Class representing a generic <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#ltn.core.Constant" title="ltn.core.Constant"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.Constant</span></code></a>(value[, trainable])</p></td>
<td><p>Class representing an LTN constant.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a>(var_label, individuals[, ...])</p></td>
<td><p>Class representing an LTN variable.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#ltn.core.Predicate" title="ltn.core.Predicate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.Predicate</span></code></a>([model, func])</p></td>
<td><p>Class representing an LTN predicate.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#ltn.core.Function" title="ltn.core.Function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.Function</span></code></a>([model, func])</p></td>
<td><p>Class representing LTN functions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.diag</span></code></a>(*vars)</p></td>
<td><p>Sets the given LTN variables for <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#ltn.core.undiag" title="ltn.core.undiag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.undiag</span></code></a>(*vars)</p></td>
<td><p>Resets the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for the given LTN variables.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#ltn.core.Connective" title="ltn.core.Connective"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.Connective</span></code></a>(connective_op)</p></td>
<td><p>Class representing an LTN connective.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#ltn.core.Quantifier" title="ltn.core.Quantifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ltn.core.Quantifier</span></code></a>(agg_op, quantifier)</p></td>
<td><p>Class representing an LTN quantifier.</p></td>
</tr>
</tbody>
</table>
<span class="target" id="module-ltn.core"></span><p>The <cite>ltn.core</cite> module contains the main functionalities of LTNtorch. In particular, it contains the definitions of
constants, variables, predicates, functions, connectives, and quantifiers.</p>
<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.LTNObject">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">LTNObject</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_labels</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.LTNObject" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Class representing a generic <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a>.</p>
<p>In LTNtorch, LTN objects are constants, variables, and outputs of predicates, formulas, functions, connectives,
and quantifiers.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>value</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a></span></dt><dd><p>The <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> (value) of the LTN object.</p>
</dd>
<dt><strong>var_labels</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a> of <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a></span></dt><dd><p>The labels of the free variables contained in the LTN object.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>in LTNtorch, the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">groundings</span></a> of the LTN objects (symbols) are represented using PyTorch tensors, namely <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a> instances;</p></li>
<li><p><cite>LTNObject</cite> is used by LTNtorch internally. The user should not create <cite>LTNObject</cite> instances by his/her own, unless strictly necessary.</p></li>
</ul>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>value</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a></span></dt><dd><p>See <cite>value</cite> parameter.</p>
</dd>
<dt><strong>free_vars</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a> of <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a></span></dt><dd><p>See <cite>var_labels</cite> parameter.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ltn.core.LTNObject.shape">
<span class="sig-name descname"><span class="pre">shape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.LTNObject.shape" title="Permalink to this definition"></a></dt>
<dd><p>Returns the shape of the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference external" href="https://pytorch.org/docs/stable/size.html#torch.Size" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Size</span></code></a></dt><dd><p>The shape of the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN object.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.Constant">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">Constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Constant" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></p>
<p>Class representing an LTN constant.</p>
<p>An LTN constant denotes an individual <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounded</span></a> as a tensor in the Real field.
The individual can be pre-defined (fixed data point) or learnable (embedding).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>value</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a></span></dt><dd><p>The <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN constant. It can be a tensor of any order.</p>
</dd>
<dt><strong>trainable</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, default=False</span></dt><dd><p>Flag indicating whether the LTN constant is trainable (embedding) or not.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>LTN constants are <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a>. <a class="reference internal" href="#ltn.core.Constant" title="ltn.core.Constant"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Constant</span></code></a> is a subclass of <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>;</p></li>
<li><p>the attribute <cite>free_vars</cite> for LTN constants is an empty list, since a constant does not have variables by definition;</p></li>
<li><p>if parameter <cite>trainable</cite> is set to <cite>True</cite>, the LTN constant becomes trainable, namely an embedding;</p></li>
<li><p>if parameter <cite>trainable</cite> is set to <cite>True</cite>, then the <cite>value</cite> attribute of the LTN constant will be used as an initialization for the embedding of the constant.</p></li>
</ul>
<p class="rubric">Examples</p>
<p>Non-trainable constant</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">,</span> <span class="mf">4.3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="go">Constant(value=tensor([3.4000, 5.4000, 4.3000]), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([3.4000, 5.4000, 4.3000])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([3])</span>
</pre></div>
</div>
<p>Trainable constant</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t_c</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">],</span>
<span class="gp">... </span>                                 <span class="p">[</span><span class="mf">6.7</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="mf">4.3</span><span class="p">]]),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t_c</span><span class="p">)</span>
<span class="go">Constant(value=tensor([[3.4000, 2.3000, 5.6000],</span>
<span class="go">        [6.7000, 5.6000, 4.3000]], requires_grad=True), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t_c</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[3.4000, 2.3000, 5.6000],</span>
<span class="go">        [6.7000, 5.6000, 4.3000]], requires_grad=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t_c</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">t_c</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.Variable">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">Variable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">var_label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">individuals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_batch_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Variable" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></p>
<p>Class representing an LTN variable.</p>
<p>An LTN variable denotes a sequence of individuals. It is <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounded</span></a> as a sequence of
tensors (<a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">groundings</span></a> of individuals) in the real field.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>var_label</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a></span></dt><dd><p>Name of the variable.</p>
</dd>
<dt><strong>individuals</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a></span></dt><dd><p>Sequence of individuals (tensors) that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> the LTN variable.</p>
</dd>
<dt><strong>add_batch_dim</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code></a>, default=True</span></dt><dd><p>Flag indicating whether a batch dimension (first dimension) has to be added to the
<cite>vale</cite> of the variable or not. If <cite>True</cite>, a dimension will be added only if the
<cite>value</cite> attribute of the LTN variable has one single dimension. In all the other cases, the first dimension
will be considered as batch dimension, so no dimension will be added.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are not correct.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the value of the <cite>var_label</cite> parameter is not correct.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>LTN variables are <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a>. <a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a> is a subclass of <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>;</p></li>
<li><p>the first dimension of an LTN variable is associated with the number of individuals in the variable, while the other dimensions are associated with the features of the individuals;</p></li>
<li><p>setting <cite>add_batch_dim</cite> to <cite>False</cite> is useful, for instance, when an LTN variable is used to denote a sequence of indexes (for example indexes for retrieving values in tensors);</p></li>
<li><p>variable labels starting with ‘_diag’ are reserved for diagonal quantification (<a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a>).</p></li>
</ul>
<p class="rubric">Examples</p>
<p><cite>add_batch_dim=True</cite> has no effects on the variable since its <cite>value</cite> has more than one dimension, namely there is
already a batch dimension.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">6.7</span><span class="p">,</span> <span class="mf">9.6</span><span class="p">]]),</span> <span class="n">add_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">Variable(value=tensor([[3.4000, 4.5000],</span>
<span class="go">        [6.7000, 9.6000]]), free_vars=[&#39;x&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[3.4000, 4.5000],</span>
<span class="go">        [6.7000, 9.6000]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
<p><cite>add_bath_dim=True</cite> adds a batch dimension to the <cite>value</cite> of the variable since it has only one dimension.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">8.9</span><span class="p">]),</span> <span class="n">add_batch_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="go">Variable(value=tensor([[3.4000],</span>
<span class="go">        [4.5000],</span>
<span class="go">        [8.9000]]), free_vars=[&#39;y&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[3.4000],</span>
<span class="go">        [4.5000],</span>
<span class="go">        [8.9000]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([3, 1])</span>
</pre></div>
</div>
<p><cite>add_batch_dim=False</cite> tells to LTNtorch to not add a batch dimension to the <cite>value</cite> of the variable. This is useful
when a variable contains a sequence of indexes.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">add_batch_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="go">Variable(value=tensor([1, 2, 3]), free_vars=[&#39;z&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([1, 2, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;z&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.Predicate">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">Predicate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Predicate" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></a></p>
<p>Class representing an LTN predicate.</p>
<p>An LTN predicate is <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounded</span></a> as a mathematical function (either pre-defined or learnable)
that maps from some n-ary domain of individuals to a real number in [0,1] (fuzzy), which can be interpreted as a
truth value.</p>
<p>In LTNtorch, the inputs of a predicate are automatically broadcasted before the computation of the predicate,
if necessary. Moreover, the output is organized in a tensor where each dimension is related to
one variable given in input. See <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for more information.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>model</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>, default=None</span></dt><dd><p>PyTorch model that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN predicate.</p>
</dd>
<dt><strong>func</strong><span class="classifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">function</span></code>, default=None</span></dt><dd><p>Function that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN predicate.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the values of the input parameters are incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>the output of an LTN predicate is always an <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a> (<a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>);</p></li>
<li><p>LTNtorch allows to define a predicate using a trainable model <strong>or</strong> a python function, not both;</p></li>
<li><p>defining a predicate using a python function is suggested only for simple and non-learnable mathematical operations;</p></li>
<li><p>examples of LTN predicates could be similarity measures, classifiers, etc;</p></li>
<li><p>the output of an LTN predicate must be always in the range [0., 1.]. Outputs outside of this range are not allowed;</p></li>
<li><p>evaluating a predicate with one variable of <span class="math notranslate nohighlight">\(n\)</span> individuals yields <span class="math notranslate nohighlight">\(n\)</span> output values, where the <span class="math notranslate nohighlight">\(i_{th}\)</span> output value corresponds to the predicate calculated with the <span class="math notranslate nohighlight">\(i_{th}\)</span> individual;</p></li>
<li><p>evaluating a predicate with <span class="math notranslate nohighlight">\(k\)</span> variables <span class="math notranslate nohighlight">\((x_1, \dots, x_k)\)</span> with respectively <span class="math notranslate nohighlight">\(n_1, \dots, n_k\)</span> individuals each, yields a result with <span class="math notranslate nohighlight">\(n_1 * \dots * n_k\)</span> values. The result is organized in a tensor where the first <span class="math notranslate nohighlight">\(k\)</span> dimensions can be indexed to retrieve the outcome(s) that correspond to each variable;</p></li>
<li><p>the attribute <cite>free_vars</cite> of the <cite>LTNobject</cite> output by the predicate tells which dimension corresponds to which variable in the <cite>value</cite> of the <cite>LTNObject</cite>. See <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for more information;</p></li>
<li><p>to disable the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>, see <a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a>.</p></li>
</ul>
<p class="rubric">Examples</p>
<p>Unary predicate defined using a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code></a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predicate_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="gp">... </span>                  <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">predicate_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="go">Predicate(model=Sequential(</span>
<span class="go">  (0): Linear(in_features=4, out_features=2, bias=True)</span>
<span class="go">  (1): ELU(alpha=1.0)</span>
<span class="go">  (2): Linear(in_features=2, out_features=1, bias=True)</span>
<span class="go">  (3): Sigmoid()</span>
<span class="go">))</span>
</pre></div>
</div>
<p>Unary predicate defined using a function. Note that <cite>torch.sum</cite> is performed on <cite>dim=1</cite>. This is because in LTNtorch
the first dimension (<cite>dim=0</cite>) is related to the batch dimension, while other dimensions are related to the features
of the individuals. Notice that the output of the print is <cite>Predicate(model=LambdaModel())</cite>. This indicates that the
LTN predicate has been defined using a function, through the <cite>func</cite> parameter of the constructor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p_f</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">p_f</span><span class="p">)</span>
<span class="go">Predicate(model=LambdaModel())</span>
</pre></div>
</div>
<p>Binary predicate defined using a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>. Note the call to <cite>torch.cat</cite> to merge
the two inputs of the binary predicate.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">PredicateModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">PredicateModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">elu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predicate_model</span> <span class="o">=</span> <span class="n">PredicateModel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_p</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">predicate_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">b_p</span><span class="p">)</span>
<span class="go">Predicate(model=PredicateModel(</span>
<span class="go">  (dense1): Linear(in_features=4, out_features=5, bias=True)</span>
<span class="go">  (dense2): Linear(in_features=5, out_features=1, bias=True)</span>
<span class="go">))</span>
</pre></div>
</div>
<p>Binary predicate defined using a function. Note the call to <cite>torch.cat</cite> to merge the two inputs of the
binary predicate.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b_p_f</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span>
<span class="gp">... </span>                                            <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>                                        <span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">b_p_f</span><span class="p">)</span>
<span class="go">Predicate(model=LambdaModel())</span>
</pre></div>
</div>
<p>Evaluation of a unary predicate on a constant. Note that:</p>
<ul class="simple">
<li><p>the predicate returns a <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a> instance;</p></li>
<li><p>since a constant has been given, the <cite>LTNObject</cite> in output does not have free variables;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is empty since the predicate has been evaluated on a constant, namely on one single individual;</p></li>
<li><p>the attribute <cite>value</cite> of the <cite>LTNObject</cite> in output contains the result of the evaluation of the predicate;</p></li>
<li><p>the <cite>value</cite> is in the range [0., 1.] since it has to be interpreted as a truth value. This is assured thanks to the <em>sigmoid function</em> in the definition of the predicate.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.34</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p_f</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
<span class="go">&lt;class &#39;ltn.core.LTNObject&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor(0.7008), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor(0.7008)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([])</span>
</pre></div>
</div>
<p>Evaluation of a unary predicate on a variable. Note that:</p>
<ul class="simple">
<li><p>since a variable has been given, the <cite>LTNObject</cite> in output has one free variable;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is 2 since the predicate has been evaluated on a variable with two individuls.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.043</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p_f</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([0.6682, 0.5898]), free_vars=[&#39;v&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([0.6682, 0.5898])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;v&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2])</span>
</pre></div>
</div>
<p>Evaluation of a binary predicate on a variable and a constant. Note that:</p>
<ul class="simple">
<li><p>like in the previous example, the <cite>LTNObject</cite> in output has just one free variable, since only one variable has been given to the predicate;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is 2 since the predicate has been evaluated on a variable with two individuals. The constant does not add dimensions to the output.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.043</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">b_p_f</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([0.8581, 0.8120]), free_vars=[&#39;v&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([0.8581, 0.8120])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;v&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2])</span>
</pre></div>
</div>
<p>Evaluation of a binary predicate on two variables. Note that:</p>
<ul class="simple">
<li><p>since two variables have been given, the <cite>LTNObject</cite> in output has two free variables;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 3)</cite> since the predicate has been evaluated on a variable with two individuals and a variable with three individuals;</p></li>
<li><p>the first dimension is dedicated to variable <cite>x</cite>, which is also the first one appearing in <cite>free_vars</cite>, while the second dimension is dedicated to variable <cite>y</cite>, which is the second one appearing in <cite>free_vars</cite>;</p></li>
<li><p>it is possible to access the <cite>value</cite> attribute for getting the results of the predicate. For example, at position <cite>(1, 2)</cite> there is the evaluation of the predicate on the second individual of <cite>x</cite> and third individuals of <cite>y</cite>.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.043</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">b_p_f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([[0.7974, 0.7790, 0.7577],</span>
<span class="go">        [0.7375, 0.7157, 0.6906]]), free_vars=[&#39;x&#39;, &#39;y&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[0.7974, 0.7790, 0.7577],</span>
<span class="go">        [0.7375, 0.7157, 0.6906]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;, &#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">tensor(0.6906)</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>model</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">function</span></code></span></dt><dd><p>The <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN predicate.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ltn.core.Predicate.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Predicate.forward" title="Permalink to this definition"></a></dt>
<dd><p>It computes the output of the predicate given some <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> in input.</p>
<p>Before computing the predicate, it performs the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> of the inputs.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>inputs</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></span></dt><dd><p>Tuple of <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> for which the predicate has to be computed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></dt><dd><p>An <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTNObject</span></a> whose <cite>value</cite> attribute contains the truth values representing the result of the
predicate, while <cite>free_vars</cite> attribute contains the labels of the free variables contained in the result.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the inputs are incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the values of the output are not in the range [0., 1.].</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.Function">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">Function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Function" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></a></p>
<p>Class representing LTN functions.</p>
<p>An LTN function is <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounded</span></a> as a mathematical function (either pre-defined or learnable)
that maps from some n-ary domain of individuals to a tensor (individual) in the Real field.</p>
<p>In LTNtorch, the inputs of a function are automatically broadcasted before the computation of the function,
if necessary. Moreover, the output is organized in a tensor where the first <span class="math notranslate nohighlight">\(k\)</span> dimensions are related
with the <span class="math notranslate nohighlight">\(k\)</span> variables given in input, while the last dimensions are related with the features of the
individual in output. See <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for more information.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>model</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>, default=None</span></dt><dd><p>PyTorch model that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN function.</p>
</dd>
<dt><strong>func</strong><span class="classifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">function</span></code>, default=None</span></dt><dd><p>Function that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN function.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the values of the input parameters are incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>the output of an LTN function is always an <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a> (<a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>);</p></li>
<li><p>LTNtorch allows to define a function using a trainable model <strong>or</strong> a python function, not both;</p></li>
<li><p>defining an LTN function using a python function is suggested only for simple and non-learnable mathematical operations;</p></li>
<li><p>examples of LTN functions could be distance functions, regressors, etc;</p></li>
<li><p>differently from LTN predicates, the output of an LTN function has no constraints;</p></li>
<li><p>evaluating a function with one variable of <span class="math notranslate nohighlight">\(n\)</span> individuals yields <span class="math notranslate nohighlight">\(n\)</span> output values, where the <span class="math notranslate nohighlight">\(i_{th}\)</span> output value corresponds to the function calculated with the <span class="math notranslate nohighlight">\(i_{th}\)</span> individual;</p></li>
<li><p>evaluating a function with <span class="math notranslate nohighlight">\(k\)</span> variables <span class="math notranslate nohighlight">\((x_1, \dots, x_k)\)</span> with respectively <span class="math notranslate nohighlight">\(n_1, \dots, n_k\)</span> individuals each, yields a result with <span class="math notranslate nohighlight">\(n_1 * \dots * n_k\)</span> values. The result is organized in a tensor where the first <span class="math notranslate nohighlight">\(k\)</span> dimensions can be indexed to retrieve the outcome(s) that correspond to each variable;</p></li>
<li><p>the attribute <cite>free_vars</cite> of the <cite>LTNobject</cite> output by the function tells which dimension corresponds to which variable in the <cite>value</cite> of the <cite>LTNObject</cite>. See <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for more information;</p></li>
<li><p>to disable the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>, see <a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a>.</p></li>
</ul>
<p class="rubric">Examples</p>
<p>Unary function defined using a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code></a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">function_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(),</span>
<span class="gp">... </span>                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>                  <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">function_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="go">Function(model=Sequential(</span>
<span class="go">  (0): Linear(in_features=4, out_features=3, bias=True)</span>
<span class="go">  (1): ELU(alpha=1.0)</span>
<span class="go">  (2): Linear(in_features=3, out_features=2, bias=True)</span>
<span class="go">))</span>
</pre></div>
</div>
<p>Unary function defined using a function. Note that <cite>torch.sum</cite> is performed on <cite>dim=1</cite>. This is because in LTNtorch
the first dimension (<cite>dim=0</cite>) is related to the batch dimension, while other dimensions are related to the features
of the individuals. Notice that the output of the print is <cite>Function(model=LambdaModel())</cite>. This indicates that the
LTN function has been defined using a function, through the <cite>func</cite> parameter of the constructor.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f_f</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
<span class="gp">... </span>                                             <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>                                        <span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">f_f</span><span class="p">)</span>
<span class="go">Function(model=LambdaModel())</span>
</pre></div>
</div>
<p>Binary function defined using a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a>. Note the call to <cite>torch.cat</cite> to merge
the two inputs of the binary function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">FunctionModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">FunctionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">elu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">dense2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">elu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">out</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">function_model</span> <span class="o">=</span> <span class="n">FunctionModel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b_f</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">function_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">b_f</span><span class="p">)</span>
<span class="go">Function(model=FunctionModel(</span>
<span class="go">  (dense1): Linear(in_features=4, out_features=5, bias=True)</span>
<span class="go">))</span>
</pre></div>
</div>
<p>Binary function defined using a function. Note the call to <cite>torch.cat</cite> to merge the two inputs of the
binary function.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b_f_f</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Function</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span>
<span class="gp">... </span>                                <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
<span class="gp">... </span>                                    <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                                    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">b_f_f</span><span class="p">)</span>
<span class="go">Function(model=LambdaModel())</span>
</pre></div>
</div>
<p>Evaluation of a unary function on a constant. Note that:</p>
<ul class="simple">
<li><p>the function returns a <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a> instance;</p></li>
<li><p>since a constant has been given, the <cite>LTNObject</cite> in output does not have free variables;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2)</cite> since the function has been evaluated on a constant, namely on one single individual, and returns individuals in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>;</p></li>
<li><p>the attribute <cite>value</cite> of the <cite>LTNObject</cite> in output contains the result of the evaluation of the function.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.34</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">f_f</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
<span class="go">&lt;class &#39;ltn.core.LTNObject&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([0.8510, 0.8510]), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([0.8510, 0.8510])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2])</span>
</pre></div>
</div>
<p>Evaluation of a unary function on a variable. Note that:</p>
<ul class="simple">
<li><p>since a variable has been given, the <cite>LTNObject</cite> in output has one free variable;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 2)</cite> since the function has been evaluated on a variable with two individuls and returns individuals in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.043</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">f_f</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([[0.7000, 0.7000],</span>
<span class="go">        [0.3630, 0.3630]]), free_vars=[&#39;v&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[0.7000, 0.7000],</span>
<span class="go">        [0.3630, 0.3630]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;v&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
<p>Evaluation of a binary function on a variable and a constant. Note that:</p>
<ul class="simple">
<li><p>like in the previous example, the <cite>LTNObject</cite> in output has just one free variable, since only one variable has been given to the predicate;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 2)</cite> since the function has been evaluated on a variable with two individuals and returns individuals in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>. The constant does not add dimensions to the output.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.043</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">b_f_f</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([[1.8000, 1.8000],</span>
<span class="go">        [1.4630, 1.4630]]), free_vars=[&#39;v&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[1.8000, 1.8000],</span>
<span class="go">        [1.4630, 1.4630]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;v&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
<p>Evaluation of a binary function on two variables. Note that:</p>
<ul class="simple">
<li><p>since two variables have been given, the <cite>LTNObject</cite> in output has two free variables;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 3, 2)</cite> since the function has been evaluated on a variable with two individuals, a variable with three individuals, and returns individuals in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>;</p></li>
<li><p>the first dimension is dedicated to variable <cite>x</cite>, which is also the first one appearing in <cite>free_vars</cite>, the second dimension is dedicated to variable <cite>y</cite>, which is the second one appearing in <cite>free_vars</cite>, while the last dimensions is dedicated to the features of the individuals in output;</p></li>
<li><p>it is possible to access the <cite>value</cite> attribute for getting the results of the function. For example, at position <cite>(1, 2)</cite> there is the evaluation of the function on the second individual of <cite>x</cite> and third individuals of <cite>y</cite>.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.32</span><span class="p">,</span> <span class="mf">0.043</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.06</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">b_f_f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([[[1.3700, 1.3700],</span>
<span class="go">         [1.2600, 1.2600],</span>
<span class="go">         [1.1400, 1.1400]],</span>

<span class="go">        [[1.0330, 1.0330],</span>
<span class="go">         [0.9230, 0.9230],</span>
<span class="go">         [0.8030, 0.8030]]]), free_vars=[&#39;x&#39;, &#39;y&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[[1.3700, 1.3700],</span>
<span class="go">         [1.2600, 1.2600],</span>
<span class="go">         [1.1400, 1.1400]],</span>

<span class="go">        [[1.0330, 1.0330],</span>
<span class="go">         [0.9230, 0.9230],</span>
<span class="go">         [0.8030, 0.8030]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;, &#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 3, 2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">tensor([0.8030, 0.8030])</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>model</strong><span class="classifier"><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></a> or <code class="xref py py-obj docutils literal notranslate"><span class="pre">function</span></code></span></dt><dd><p>The <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN function.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ltn.core.Function.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Function.forward" title="Permalink to this definition"></a></dt>
<dd><p>It computes the output of the function given some <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> in input.</p>
<p>Before computing the function, it performs the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> of the inputs.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>inputs</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></span></dt><dd><p>Tuple of <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> for which the function has to be computed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></dt><dd><p>An <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTNObject</span></a> whose <cite>value</cite> attribute contains the result of the
function, while <cite>free_vars</cite> attribute contains the labels of the free variables contained in the result.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the inputs are incorrect.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ltn.core.diag">
<span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">diag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">vars</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.diag" title="Permalink to this definition"></a></dt>
<dd><p>Sets the given LTN variables for <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a>.</p>
<p>The diagonal quantification disables the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for the given variables.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>vars</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a></span></dt><dd><p>Tuple of LTN variables for which the diagonal quantification has to be set.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a> of <a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a></dt><dd><p>List of the same LTN variables given in input, prepared for the use of <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a>.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the values of the input parameters are incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ltn.core.undiag" title="ltn.core.undiag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.undiag()</span></code></a></dt><dd><p>It allows to disable the diagonal quantification for the given variables.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>diagonal quantification has been designed to work with quantified statements, however, it could be used also to reduce the combinations of individuals for which a predicate has to be computed, making the computation more efficient;</p></li>
<li><p>diagonal quantification is particularly useful when we need to compute a predicate, or function, on specific tuples of variables’ individuals only;</p></li>
<li><p>diagonal quantification expects the given variables to have the same number of individuals.</p></li>
</ul>
<p class="rubric">Examples</p>
<p>Behavior of a predicate without diagonal quantification. Note that:</p>
<ul class="simple">
<li><p>if diagonal quantification is not used, LTNtorch applies the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> to the variables before computing the predicate;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 2)</cite> since the predicate has been computed on two variables with two individuals each;</p></li>
<li><p>the <cite>free_vars</cite> attribute of the <cite>LTNObject</cite> in output contains two variables, namely the variables on which the predicate has been computed.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span>
<span class="gp">... </span>                                        <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>                                    <span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.56</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.004</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[0.8447, 0.8710],</span>
<span class="go">        [0.7763, 0.8115]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;, &#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
<p>Behavior of the same predicate with diagonal quantification. Note that:</p>
<ul class="simple">
<li><p>diagonal quantification requires the two variables to have the same number of individuals;</p></li>
<li><p>diagonal quantification has disabled the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>, namely the predicate is not computed on all the possible combinations of individuals of the two variables (that are 2x2). Instead, it is computed only on the given tuples of individuals (that are 2), namely on the first individual of <cite>x</cite> and first individual of <cite>y</cite>, and on the second individual of <cite>x</cite> and second individual of <cite>y</cite>;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2)</cite> since diagonal quantification has been set and the variables have two individuals;</p></li>
<li><p>the <cite>free_vars</cite> attribute of the <cite>LTNObject</cite> in output has just one variable, even if two variables have been given to the predicate. This is due to diagonal quantification;</p></li>
<li><p>when diagonal quantification is set, you will se a variable label starting with <cite>diag_</cite> in the <cite>free_Vars</cite> attribute.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([0.8447, 0.8115])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;diag_x_y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2])</span>
</pre></div>
</div>
<p>See the examples under <a class="reference internal" href="#ltn.core.Quantifier" title="ltn.core.Quantifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Quantifier</span></code></a> to see how to use <a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a> with quantifiers.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="ltn.core.undiag">
<span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">undiag</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">vars</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.undiag" title="Permalink to this definition"></a></dt>
<dd><p>Resets the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for the given LTN variables.</p>
<p>In other words, it removes the <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a> setting from the given variables.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>vars</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a></span></dt><dd><p>Tuple of LTN variables for which the <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a> setting has to be removed.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a></dt><dd><p>List of the same LTN variables given in input, with the <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a> setting removed.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a></dt><dd><p>It allows to set the <a class="reference internal" href="quantification.html#diagonal"><span class="std std-ref">diagonal quantification</span></a> for the given variables.</p>
</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>Behavior of predicate with diagonal quantification. Note that:</p>
<ul class="simple">
<li><p>diagonal quantification requires the two variables to have the same number of individuals;</p></li>
<li><p>diagonal quantification has disabled the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>, namely the predicate is not computed on all the possible combinations of individuals of the two variables (that are 2x2). Instead, it is computed only on the given tuples of individuals (that are 2), namely on the first individual of <cite>x</cite> and first individual of <cite>y</cite>, and on the second individual of <cite>x</cite> and second individual of <cite>y</cite>;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2)</cite> since diagonal quantification has been set and the variables have two individuals;</p></li>
<li><p>the <cite>free_vars</cite> attribute of the <cite>LTNObject</cite> in output has just one variable, even if two variables have been given to the predicate. This is due to diagonal quantification;</p></li>
<li><p>when diagonal quantification is set, you will se a variable label starting with <cite>diag_</cite> in the <cite>free_Vars</cite> attribute.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span>
<span class="gp">... </span>                                        <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>                                    <span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.56</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.004</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([0.8447, 0.8115])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;diag_x_y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2])</span>
</pre></div>
</div>
<p><a class="reference internal" href="#ltn.core.undiag" title="ltn.core.undiag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.undiag()</span></code></a> can be used to restore the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for the two variables. In
the following, it is shown the behavior of the same predicate without diagonal quantification. Note that:</p>
<ul class="simple">
<li><p>since diagonal quantification has been disabled, LTNtorch applies the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> to the variables before computing the predicate;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 2)</cite> since the predicate has been computed on two variables with two individuals each;</p></li>
<li><p>the <cite>free_vars</cite> attribute of the <cite>LTNObject</cite> in output contains two variables, namely the variables on which the predicate has been computed.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">undiag</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[0.8447, 0.8710],</span>
<span class="go">        [0.7763, 0.8115]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;, &#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 2])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.Connective">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">Connective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">connective_op</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Connective" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Class representing an LTN connective.</p>
<p>An LTN connective is <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounded</span></a> as a fuzzy connective operator.</p>
<p>In LTNtorch, the inputs of a connective are automatically broadcasted before the computation of the connective,
if necessary. Moreover, the output is organized in a tensor where each dimension is related to
one variable appearing in the inputs. See <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> for more information.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>connective_op</strong><span class="classifier"><a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.ConnectiveOperator" title="ltn.fuzzy_ops.ConnectiveOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.ConnectiveOperator</span></code></a></span></dt><dd><p>The unary/binary fuzzy connective operator that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN connective.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the type of the input parameter is incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="fuzzy_ops.html#module-ltn.fuzzy_ops" title="ltn.fuzzy_ops"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops</span></code></a></dt><dd><p>The <cite>ltn.fuzzy_ops</cite> module contains the definition of common fuzzy connective operators that can be used with LTN connectives.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>the LTN connective supports various fuzzy connective operators. They can be found in <a class="reference internal" href="fuzzy_ops.html#fuzzyop"><span class="std std-ref">ltn.fuzzy_ops</span></a>;</p></li>
<li><p>the LTN connective allows to use these fuzzy operators with LTN formulas. It takes care of combining sub-formulas which have different variables appearing in them (<a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a>).</p></li>
<li><p>an LTN connective can be applied only to <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> containing truth values, namely values in <span class="math notranslate nohighlight">\([0., 1.]\)</span>;</p></li>
<li><p>the output of an LTN connective is always an <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a> (<a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>).</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="ltn.core.Connective.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">operands</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Connective.__call__" title="Permalink to this definition"></a></dt>
<dd><p>It applies the selected fuzzy connective operator (<cite>connective_op</cite> attribute) to the operands
(<a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a>) given in input.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>operands</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tuple</span></code></a> of <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></span></dt><dd><p>Tuple of <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> representing the operands to which the fuzzy connective
operator has to be applied.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></dt><dd><p>The <cite>LTNObject</cite> that is the result of the application of the fuzzy connective operator to the given
<a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a>.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the values of the input parameters are incorrect.
Raises when the truth values of the operands given in input are not in the range [0., 1.].</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p>Use of <span class="math notranslate nohighlight">\(\land\)</span> to create a formula which is the conjunction of two predicates. Note that:</p>
<ul class="simple">
<li><p>a connective operator can be applied only to inputs which represent truth values. In this case with have two predicates;</p></li>
<li><p>LTNtorch provides various semantics for the conjunction, here we use the Goguen conjunction (<a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.AndProd" title="ltn.fuzzy_ops.AndProd"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.AndProd</span></code></a>);</p></li>
<li><p>LTNtorch applies the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> to the variables before computing the predicates;</p></li>
<li><p>LTNtorch applies the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN brodcasting</span></a> to the operands before applying the selected conjunction operator;</p></li>
<li><p>the result of a connective operator is a <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a> instance containing truth values in [0., 1.];</p></li>
<li><p>the attribute <cite>value</cite> of the <cite>LTNObject</cite> in output contains the result of the connective operator;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 3, 4)</cite>. The first dimension is associated with variable <cite>x</cite>, which has two individuals, the second dimension with variable <cite>y</cite>, which has three individuals, while the last dimension with variable <cite>z</cite>, which has four individuals;</p></li>
<li><p>it is possible to access to specific results by indexing the attribute <cite>value</cite>. For example, at index <cite>(0, 1, 2)</cite> there is the evaluation of the formula on the first individual of <cite>x</cite>, second individual of <cite>y</cite>, and third individual of <cite>z</cite>;</p></li>
<li><p>the attribute <cite>free_vars</cite> of the <cite>LTNObject</cite> in output contains the labels of the three variables appearing in the formula.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span>
<span class="gp">... </span>                                    <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>                                 <span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span>
<span class="gp">... </span>                                        <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                                    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.23</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">4.3</span><span class="p">,</span> <span class="mf">9.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">4.3</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;z&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">4.3</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">4.3</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">And</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Connective</span><span class="p">(</span><span class="n">ltn</span><span class="o">.</span><span class="n">fuzzy_ops</span><span class="o">.</span><span class="n">AndProd</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">And</span><span class="p">)</span>
<span class="go">Connective(connective_op=AndProd(stable=True))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">And</span><span class="p">(</span><span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">q</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([[[0.5971, 0.6900, 0.6899, 0.6391],</span>
<span class="go">         [0.6900, 0.6900, 0.6900, 0.6900],</span>
<span class="go">         [0.6878, 0.6900, 0.6900, 0.6889]],</span>

<span class="go">        [[0.5325, 0.6154, 0.6153, 0.5700],</span>
<span class="go">         [0.6154, 0.6154, 0.6154, 0.6154],</span>
<span class="go">         [0.6135, 0.6154, 0.6154, 0.6144]]]), free_vars=[&#39;x&#39;, &#39;y&#39;, &#39;z&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[[0.5971, 0.6900, 0.6899, 0.6391],</span>
<span class="go">         [0.6900, 0.6900, 0.6900, 0.6900],</span>
<span class="go">         [0.6878, 0.6900, 0.6900, 0.6889]],</span>

<span class="go">        [[0.5325, 0.6154, 0.6153, 0.5700],</span>
<span class="go">         [0.6154, 0.6154, 0.6154, 0.6154],</span>
<span class="go">         [0.6135, 0.6154, 0.6154, 0.6144]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;, &#39;y&#39;, &#39;z&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 3, 4])</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>connective_op</strong><span class="classifier"><a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.ConnectiveOperator" title="ltn.fuzzy_ops.ConnectiveOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.ConnectiveOperator</span></code></a></span></dt><dd><p>See <cite>connective_op</cite> parameter.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ltn.core.Quantifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ltn.core.</span></span><span class="sig-name descname"><span class="pre">Quantifier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">agg_op</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantifier</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Quantifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Class representing an LTN quantifier.</p>
<p>An LTN quantifier is <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounded</span></a> as a fuzzy aggregation operator. See <a class="reference internal" href="quantification.html#quantification"><span class="std std-ref">quantification in LTN</span></a>
for more information about quantification.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>agg_op</strong><span class="classifier"><a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.AggregationOperator" title="ltn.fuzzy_ops.AggregationOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.AggregationOperator</span></code></a></span></dt><dd><p>The fuzzy aggregation operator that becomes the <a class="reference internal" href="grounding.html#notegrounding"><span class="std std-ref">grounding</span></a> of the LTN quantifier.</p>
</dd>
<dt><strong>quantifier</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a></span></dt><dd><p>String indicating the quantification that has to be performed (‘e’ for ∃, or ‘f’ for ∀).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the type of the <cite>agg_op</cite> parameter is incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the value of the <cite>quantifier</cite> parameter is incorrect.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="fuzzy_ops.html#module-ltn.fuzzy_ops" title="ltn.fuzzy_ops"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops</span></code></a></dt><dd><p>The <cite>ltn.fuzzy_ops</cite> module contains the definition of common fuzzy aggregation operators that can be used with LTN quantifiers.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>the LTN quantifier supports various fuzzy aggregation operators, which can be found in <a class="reference internal" href="fuzzy_ops.html#module-ltn.fuzzy_ops" title="ltn.fuzzy_ops"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops</span></code></a>;</p></li>
<li><p>the LTN quantifier allows to use these fuzzy aggregators with LTN formulas. It takes care of selecting the formula (<cite>LTNObject</cite>) dimensions to aggregate, given some LTN variables in arguments.</p></li>
<li><p>boolean conditions (by setting parameters <cite>mask_fn</cite> and <cite>mask_vars</cite>) can be used for <a class="reference internal" href="quantification.html#guarded"><span class="std std-ref">guarded quantification</span></a>;</p></li>
<li><p>an LTN quantifier can be applied only to <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN objects</span></a> containing truth values, namely values in <span class="math notranslate nohighlight">\([0., 1.]\)</span>;</p></li>
<li><p>the output of an LTN quantifier is always an <a class="reference internal" href="ltnobjects.html#noteltnobject"><span class="std std-ref">LTN object</span></a> (<a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a>).</p></li>
</ul>
<dl class="py method">
<dt class="sig sig-object py" id="ltn.core.Quantifier.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vars</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">formula</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cond_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cond_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ltn.core.Quantifier.__call__" title="Permalink to this definition"></a></dt>
<dd><p>It applies the selected aggregation operator (<cite>agg_op</cite> attribute) to the formula given in input based on the
selected variables.</p>
<p>It allows also to perform a <a class="reference internal" href="quantification.html#guarded"><span class="std std-ref">guarded quantification</span></a> by setting <cite>cond_vars</cite> and <cite>cond_fn</cite>
parameters.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>vars</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a> of <a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a></span></dt><dd><p>List of LTN variables on which the quantification has to be performed.</p>
</dd>
<dt><strong>formula</strong><span class="classifier"><a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a></span></dt><dd><p>Formula on which the quantification has to be performed.</p>
</dd>
<dt><strong>cond_vars</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">list</span></code></a> of <a class="reference internal" href="#ltn.core.Variable" title="ltn.core.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.Variable</span></code></a>, default=None</span></dt><dd><p>List of LTN variables that appear in the <a class="reference internal" href="quantification.html#guarded"><span class="std std-ref">guarded quantification</span></a> condition.</p>
</dd>
<dt><strong>cond_fn</strong><span class="classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">function</span></code>, default=None</span></dt><dd><p>Function representing the <a class="reference internal" href="quantification.html#guarded"><span class="std std-ref">guarded quantification</span></a> condition.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#TypeError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">TypeError</span></code></a></dt><dd><p>Raises when the types of the input parameters are incorrect.</p>
</dd>
<dt><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a></dt><dd><p>Raises when the values of the input parameters are incorrect.
Raises when the truth values of the formula given in input are not in the range [0., 1.].</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<p>Behavior of a binary predicate evaluated on two variables. Note that:</p>
<ul class="simple">
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(2, 3)</cite> since the predicate has been computed on a variable with two individuals and a variable with three individuals;</p></li>
<li><p>the attribute <cite>free_vars</cite> of the <cite>LTNObject</cite> in output contains the labels of the two variables given in input to the predicate.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">ltn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Predicate</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()(</span>
<span class="gp">... </span>                                        <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="gp">... </span>                                    <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">3.4</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([[0.9900, 0.9994, 0.9988],</span>
<span class="go">        [0.9734, 0.9985, 0.9967]]), free_vars=[&#39;x&#39;, &#39;y&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([[0.9900, 0.9994, 0.9988],</span>
<span class="go">        [0.9734, 0.9985, 0.9967]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;x&#39;, &#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([2, 3])</span>
</pre></div>
</div>
<p>Universal quantification on one single variable of the same predicate. Note that:</p>
<ul class="simple">
<li><p><cite>quantifier=’f’</cite> means that we are defining the fuzzy semantics for the universal quantifier;</p></li>
<li><p>the result of a quantification operator is always a <a class="reference internal" href="#ltn.core.LTNObject" title="ltn.core.LTNObject"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.core.LTNObject</span></code></a> instance;</p></li>
<li><p>LTNtorch supports various sematics for quantifiers, here we use <a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.AggregPMeanError" title="ltn.fuzzy_ops.AggregPMeanError"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.AggregPMeanError</span></code></a> for <span class="math notranslate nohighlight">\(\forall\)</span>;</p></li>
<li><p>the shape of the <cite>LTNObject</cite> in output is <cite>(3)</cite> since the quantification has been performed on variable <cite>x</cite>. Only the dimension associated with variable <cite>y</cite> has left since the quantification has been computed by LTNtorch as an aggregation on the dimension related with variable <cite>x</cite>;</p></li>
<li><p>the attribute <cite>free_vars</cite> of the <cite>LTNObject</cite> in output contains only the label of variable <cite>y</cite>. This is because variable <cite>x</cite> has been quantified, namely it is not a free variable anymore;</p></li>
<li><p>in LTNtorch, the quantification is performed by computing the value of the predicate first and then by aggregating on the selected dimensions, specified by the quantified variables.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Forall</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Quantifier</span><span class="p">(</span><span class="n">ltn</span><span class="o">.</span><span class="n">fuzzy_ops</span><span class="o">.</span><span class="n">AggregPMeanError</span><span class="p">(),</span> <span class="n">quantifier</span><span class="o">=</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">Forall</span><span class="p">)</span>
<span class="go">Quantifier(agg_op=AggregPMeanError(p=2, stable=True), quantifier=&#39;f&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Forall</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor([0.9798, 0.9988, 0.9974]), free_vars=[&#39;y&#39;])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor([0.9798, 0.9988, 0.9974])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[&#39;y&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([3])</span>
</pre></div>
</div>
<p>Universal quantification on both variables of the same predicate. Note that:</p>
<ul class="simple">
<li><p>the shape of the <cite>LTNObject</cite> in output is empty since the quantification has been performed on both variables. No dimension has left since the quantification has been computed by LTNtorch as an aggregation on both dimensions of the <cite>value</cite> of the predicate;</p></li>
<li><p>the attribute <cite>free_vars</cite> of the <cite>LTNObject</cite> in output contains no labels of variables. This is because both variables have been quantified, namely they are not free variables anymore.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Forall</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor(0.9882), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor(0.9882)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([])</span>
</pre></div>
</div>
<p>Universal quantification on one variable, and existential quantification on the other variable, of the same predicate.
Note that:</p>
<ul class="simple">
<li><p>the only way in LTNtorch to apply two different quantifiers to the same formula is a nested syntax;</p></li>
<li><p><cite>quantifier=’e’</cite> means that we are defining the fuzzy semantics for the existential quantifier;</p></li>
<li><p>LTNtorch supports various sematics for quantifiers, here we use <a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.AggregPMean" title="ltn.fuzzy_ops.AggregPMean"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.AggregPMean</span></code></a> for <span class="math notranslate nohighlight">\(\exists\)</span>.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Exists</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Quantifier</span><span class="p">(</span><span class="n">ltn</span><span class="o">.</span><span class="n">fuzzy_ops</span><span class="o">.</span><span class="n">AggregPMean</span><span class="p">(),</span> <span class="n">quantifier</span><span class="o">=</span><span class="s1">&#39;e&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">Exists</span><span class="p">)</span>
<span class="go">Quantifier(agg_op=AggregPMean(p=2, stable=True), quantifier=&#39;e&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Forall</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Exists</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor(0.9920), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor(0.9920)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([])</span>
</pre></div>
</div>
<p>Guarded quantification. We perform a universal quantification on both variables of the same predicate, considering
only the individuals of variable <cite>x</cite> whose sum of features is lower than a certain threshold. Note that:</p>
<ul class="simple">
<li><p>guarded quantification requires the parameters <cite>cond_vars</cite> and <cite>cond_fn</cite> to be set;</p></li>
<li><p><cite>cond_vars</cite> contains the variables on which the guarded condition is based on. In this case, we have decided to create a condition on <cite>x</cite>;</p></li>
<li><p><cite>cond_fn</cite> contains the function which is the guarded condition. In this case, it verifies if the sum of features of the individuals of <cite>x</cite> is lower than 1. (our threshold);</p></li>
<li><p>the second individual of <cite>x</cite>, which is <cite>[0.3, 0.3]</cite>, satisfies the condition, namely it will not be considered when the aggregation has to be performed. In other words, all the results of the predicate computed using the second individual of <cite>x</cite> will not be considered in the aggregation;</p></li>
<li><p>notice the result changes compared to the previous example (<span class="math notranslate nohighlight">\(\forall x \forall y P(x, y)\)</span>). This is due to the fact that some truth values of the result of the predicate are not considered in the aggregation due to guarded quantification. These values are at positions <cite>(1, 0)</cite>, <cite>(1, 1)</cite>, and <cite>(1, 2)</cite>, namely all the positions related with the second individual of <cite>x</cite> in the result of the predicate;</p></li>
<li><p>notice that the shape of the <cite>LTNObject</cite> in output and its attribute <cite>free_vars</cite> remain the same compared to the previous example. This is because the quantification is still on both variables, namely it is perfomed on both dimensions of the result of the predicate.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Forall</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span>
<span class="gp">... </span>            <span class="n">cond_vars</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">],</span>
<span class="gp">... </span>            <span class="n">cond_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="mf">1.</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor(0.9844, dtype=torch.float64), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor(0.9844, dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([])</span>
</pre></div>
</div>
<p>Universal quantification of both variables of the same predicate using diagonal quantification
(<a class="reference internal" href="#ltn.core.diag" title="ltn.core.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">ltn.core.diag()</span></code></a>). Note that:</p>
<ul class="simple">
<li><p>the variables have the same number of individuals since it is a constraint for applying diagonal quantification;</p></li>
<li><p>since diagonal quantification has been set, the predicate will not be computed on all the possible combinations of individuals of the two variables (that are 4), namely the <a class="reference internal" href="broadcasting.html#broadcasting"><span class="std std-ref">LTN broadcasting</span></a> is disabled;</p></li>
<li><p>the predicate is computed only on the given tuples of individuals in a one-to-one correspondence, namely on the first individual of <cite>x</cite> and <cite>y</cite>, and second individual of <cite>x</cite> and <cite>y</cite>;</p></li>
<li><p>the result changes compared to the case without diagonal quantification. This is due to the fact that we are aggregating a smaller number of truth values since the predicate has been computed only two times.</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">],</span>
<span class="gp">... </span>                                    <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ltn</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">2.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
<span class="gp">... </span>                                   <span class="p">[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">3.4</span><span class="p">]]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">Forall</span><span class="p">(</span><span class="n">ltn</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span> <span class="c1"># with diagonal quantification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_without_diag</span> <span class="o">=</span> <span class="n">Forall</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span> <span class="c1"># without diagonal quantification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out_without_diag</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor(0.9788), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out_without_diag</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor(0.9788)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="go">LTNObject(value=tensor(0.9888), free_vars=[])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">tensor(0.9888)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">free_vars</span><span class="p">)</span>
<span class="go">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">())</span>
<span class="go">torch.Size([])</span>
</pre></div>
</div>
<dl class="field-list">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl>
<dt><strong>agg_op</strong><span class="classifier"><a class="reference internal" href="fuzzy_ops.html#ltn.fuzzy_ops.AggregationOperator" title="ltn.fuzzy_ops.AggregationOperator"><code class="xref py py-class docutils literal notranslate"><span class="pre">ltn.fuzzy_ops.AggregationOperator</span></code></a></span></dt><dd><p>See <cite>agg_op</cite> parameter.</p>
</dd>
<dt><strong>quantifier</strong><span class="classifier"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code></a></span></dt><dd><p>See <cite>quantifier</cite> parameter.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="stableconf.html" class="btn btn-neutral float-left" title="Stable Fuzzy Semantics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="fuzzy_ops.html" class="btn btn-neutral float-right" title="ltn.fuzzy_ops" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Tommaso Carraro.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>